{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EP7: update_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(input_url, output_file):\n",
    "    \"\"\"\n",
    "    Donwload a file from an url and save it under the specified path and name.\n",
    "    Args:\n",
    "    - input_url: url of the file to download\n",
    "    - output_file: path and name of the file to save.\n",
    "    \"\"\"\n",
    "    response = requests.get(input_url)\n",
    "    if response.status_code == 200:\n",
    "        # Process the response content as needed\n",
    "        content = response.text\n",
    "        text_file = open(output_file, \"wb\")\n",
    "        text_file.write(content.encode(\"utf-8\"))  # to be check...\n",
    "        text_file.close()\n",
    "        print(f\"{output_file} loaded\")\n",
    "    else:\n",
    "        print(f\"Error accessing the object {input_url}:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/raw\"\n",
    "http_url = \"https://www.data.gouv.fr/fr/datasets/r/\"\n",
    "year_list = [2019, 2020]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw\\ressources.csv loaded\n"
     ]
    }
   ],
   "source": [
    "# download list of ressources from gouv.fr\n",
    "output_file = os.path.join(output_path, \"ressources.csv\")\n",
    "download_file(\"https://www.data.gouv.fr/resources.csv\", output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['caracteristiques-2019.csv',\n",
       " 'caracteristiques-2020.csv',\n",
       " 'lieux-2019.csv',\n",
       " 'lieux-2020.csv',\n",
       " 'usagers-2019.csv',\n",
       " 'usagers-2020.csv',\n",
       " 'vehicules-2019.csv',\n",
       " 'vehicules-2020.csv']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download data files according to the year list\n",
    "file_list_template = [\"caracteristiques\", \"lieux\",\"usagers\", \"vehicules\"]\n",
    "data_files_list = [f'{item}-{year}.csv' for item in file_list_template for year in year_list]\n",
    "data_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/raw\\usagers-2020.csv loaded\n",
      "../data/raw\\vehicules-2020.csv loaded\n",
      "../data/raw\\lieux-2020.csv loaded\n",
      "../data/raw\\caracteristiques-2020.csv loaded\n",
      "../data/raw\\usagers-2019.csv loaded\n",
      "../data/raw\\vehicules-2019.csv loaded\n",
      "../data/raw\\lieux-2019.csv loaded\n",
      "../data/raw\\caracteristiques-2019.csv loaded\n"
     ]
    }
   ],
   "source": [
    "with open(output_file, \"r\", encoding=\"utf-8\") as my_file:\n",
    "    contents = my_file.readline()\n",
    "    while contents:\n",
    "        for filename in data_files_list:\n",
    "            if filename in contents:\n",
    "                 # 9 = ressource id\n",
    "                input_url = http_url + contents.split(\";\")[9][1:-1]\n",
    "                output_data_file = os.path.join(output_path, filename)\n",
    "                download_file(input_url, output_data_file)\n",
    "                break\n",
    "        contents = my_file.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Concaténation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove resources.csv:\n",
    "os.remove(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_if_necessary(path):\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "            return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = \"../\"\n",
    "interim_path = create_folder_if_necessary(os.path.join(root_path, \"data\", \"interim\"))\n",
    "raw_path = create_folder_if_necessary(os.path.join(root_path, \"data\", \"raw\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019', '2020', '2021']\n"
     ]
    }
   ],
   "source": [
    "# Get existing years in data/raw files:\n",
    "year_list = []\n",
    "for filename in os.listdir(\"../data/raw\"):\n",
    "    year = filename[-8:-4]\n",
    "    if year not in year_list:\n",
    "        year_list.append(year)\n",
    "print(year_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AlexW\\AppData\\Local\\Temp\\ipykernel_19420\\283191079.py:3: DtypeWarning: Columns (12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(\"../data/interim/lieux.csv\", sep = \";\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteristiques: (163102, 15)\n",
      "Lieux: (163102, 18)\n",
      "Usagers: (367425, 15)\n",
      "Vehicules: (279091, 11)\n"
     ]
    }
   ],
   "source": [
    "# Test jupyter\n",
    "df1 = pd.read_csv(\"../data/interim/caracteristiques.csv\", sep = \";\")\n",
    "df2 = pd.read_csv(\"../data/interim/lieux.csv\", sep = \";\")\n",
    "df3 = pd.read_csv(\"../data/interim/usagers.csv\", sep = \";\")\n",
    "df4 = pd.read_csv(\"../data/interim/vehicules.csv\", sep = \";\")\n",
    "\n",
    "print(\"Caracteristiques:\", df1.shape)\n",
    "print(\"Lieux:\", df2.shape)\n",
    "print(\"Usagers:\", df3.shape)\n",
    "print(\"Vehicules:\", df4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AlexW\\AppData\\Local\\Temp\\ipykernel_19420\\614729178.py:1: DtypeWarning: Columns (12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"../data/interim/lieux.csv\", sep = \";\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/interim/lieux.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all downloaded files in data/raw_merged: useless?\n",
    "# for file_template in file_list_template:\n",
    "    # for year in year_list:\n",
    "        # src = os.path.join(raw_path, f\"{file_template}-{year}.csv\")\n",
    "        # dest = os.path.join(interim_path, f\"{file_template}-{year}.csv\")\n",
    "        # shutil.copyfile(src, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge files:\n",
    "for file_template in file_list_template:\n",
    "    output_filename = os.path.join(interim_path, f\"{file_template}.csv\")\n",
    "    with open(output_filename, \"w\") as merged_file:\n",
    "        for index, year in enumerate(year_list):\n",
    "            input_filename = os.path.join(raw_path, f\"{file_template}-{year}.csv\")\n",
    "            with open(input_filename, \"r\") as file:\n",
    "                if index != 0:\n",
    "                    file.readline()  # Throw away header on all but first file\n",
    "                merged_file.write(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracteristiques: (163102, 15)\n",
      "Lieux: (163102, 18)\n",
      "Usagers: (367425, 15)\n",
      "Vehicules: (279091, 11)\n"
     ]
    }
   ],
   "source": [
    "# Test jupyter\n",
    "df1 = pd.read_csv(\"../data/interim/caracteristiques.csv\", sep = \";\")\n",
    "df2 = pd.read_csv(\"../data/interim/lieux.csv\", sep = \";\", low_memory=False)\n",
    "df3 = pd.read_csv(\"../data/interim/usagers.csv\", sep = \";\")\n",
    "df4 = pd.read_csv(\"../data/interim/vehicules.csv\", sep = \";\")\n",
    "\n",
    "print(\"Caracteristiques:\", df1.shape)\n",
    "print(\"Lieux:\", df2.shape)\n",
    "print(\"Usagers:\", df3.shape)\n",
    "print(\"Vehicules:\", df4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le merge a bien eu lieu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing des nouvelles données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filepath_users = os.path.join(interim_path, \"usagers.csv\")\n",
    "input_filepath_caract = os.path.join(interim_path, \"caracteristiques.csv\")\n",
    "input_filepath_places = os.path.join(interim_path, \"lieux.csv\")\n",
    "input_filepath_veh = os.path.join(interim_path, \"vehicules.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "root_path = \"../\"\n",
    "sys.path.append(os.path.join(root_path, \"src\", \"data\"))\n",
    "from make_dataset import main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AlexW\\Documents\\GitHub\\shield\\notebooks\\../src\\data\\make_dataset.py:43: DtypeWarning: Columns (12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_places = pd.read_csv(input_filepath_places, sep=\";\", encoding='utf-8')\n",
      "c:\\Users\\AlexW\\Documents\\GitHub\\shield\\notebooks\\../src\\data\\make_dataset.py:60: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_users.grav.replace([1, 2, 3, 4], [1, 3, 4, 2], inplace=True)\n",
      "c:\\Users\\AlexW\\Documents\\GitHub\\shield\\notebooks\\../src\\data\\make_dataset.py:86: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_veh['catv'].replace(catv_value, catv_value_new, inplace=True)\n",
      "c:\\Users\\AlexW\\Documents\\GitHub\\shield\\notebooks\\../src\\data\\make_dataset.py:104: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['grav'].replace([2, 3, 4], [0, 1, 1], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "main(input_filepath=\"../data/interim\",\n",
    "     output_filepath=\"../data/preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
